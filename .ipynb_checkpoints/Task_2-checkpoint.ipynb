{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:523: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:524: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:532: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing and preprocessing the training set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Applying image augmentation to avoid overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Preparing the class list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_list = []\n",
    "num = 48\n",
    "cap = 65\n",
    "small = 97\n",
    "for i in range(0, 62):\n",
    "    if i <= 9:\n",
    "        class_list.append(chr(num))\n",
    "        num = num + 1\n",
    "    elif i > 9 and i <= 35:\n",
    "        class_list.append(chr(cap))\n",
    "        cap = cap + 1\n",
    "    else:\n",
    "        class_list.append(chr(small))\n",
    "        small = small + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '3', '4', '5', '6', '7', '8', '9', 'A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z', 'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l', 'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x', 'y', 'z']\n"
     ]
    }
   ],
   "source": [
    "print(class_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2480 images belonging to 62 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = train_datagen.flow_from_directory(\n",
    "    'Training_Set',\n",
    "    target_size=(28, 28),\n",
    "    batch_size=32,\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Sample001': 0,\n",
       " 'Sample002': 1,\n",
       " 'Sample003': 2,\n",
       " 'Sample004': 3,\n",
       " 'Sample005': 4,\n",
       " 'Sample006': 5,\n",
       " 'Sample007': 6,\n",
       " 'Sample008': 7,\n",
       " 'Sample009': 8,\n",
       " 'Sample010': 9,\n",
       " 'Sample011': 10,\n",
       " 'Sample012': 11,\n",
       " 'Sample013': 12,\n",
       " 'Sample014': 13,\n",
       " 'Sample015': 14,\n",
       " 'Sample016': 15,\n",
       " 'Sample017': 16,\n",
       " 'Sample018': 17,\n",
       " 'Sample019': 18,\n",
       " 'Sample020': 19,\n",
       " 'Sample021': 20,\n",
       " 'Sample022': 21,\n",
       " 'Sample023': 22,\n",
       " 'Sample024': 23,\n",
       " 'Sample025': 24,\n",
       " 'Sample026': 25,\n",
       " 'Sample027': 26,\n",
       " 'Sample028': 27,\n",
       " 'Sample029': 28,\n",
       " 'Sample030': 29,\n",
       " 'Sample031': 30,\n",
       " 'Sample032': 31,\n",
       " 'Sample033': 32,\n",
       " 'Sample034': 33,\n",
       " 'Sample035': 34,\n",
       " 'Sample036': 35,\n",
       " 'Sample037': 36,\n",
       " 'Sample038': 37,\n",
       " 'Sample039': 38,\n",
       " 'Sample040': 39,\n",
       " 'Sample041': 40,\n",
       " 'Sample042': 41,\n",
       " 'Sample043': 42,\n",
       " 'Sample044': 43,\n",
       " 'Sample045': 44,\n",
       " 'Sample046': 45,\n",
       " 'Sample047': 46,\n",
       " 'Sample048': 47,\n",
       " 'Sample049': 48,\n",
       " 'Sample050': 49,\n",
       " 'Sample051': 50,\n",
       " 'Sample052': 51,\n",
       " 'Sample053': 52,\n",
       " 'Sample054': 53,\n",
       " 'Sample055': 54,\n",
       " 'Sample056': 55,\n",
       " 'Sample057': 56,\n",
       " 'Sample058': 57,\n",
       " 'Sample059': 58,\n",
       " 'Sample060': 59,\n",
       " 'Sample061': 60,\n",
       " 'Sample062': 61}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_set.class_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the CNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the Convolution Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu', input_shape=[28, 28, 1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the Pooling Layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding another hidden layer of Convolution and Pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Conv2D(filters=16, kernel_size=3, activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a flattening layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Flatten())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding a following dense neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=128, activation='relu'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding the final output layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.layers.Dense(units=62, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "cnn.compile(optimizer='adam', loss='categorical_crossentropy', metrics=[keras.metrics.AUC(), keras.metrics.Precision(), keras.metrics.Recall()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/25\n",
      "78/78 [==============================] - 73s 932ms/step - loss: 4.1297 - auc_1: 0.5028 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00\n",
      "Epoch 2/25\n",
      "78/78 [==============================] - 22s 286ms/step - loss: 3.9667 - auc_1: 0.5423 - precision_1: 0.0000e+00 - recall_1: 0.0000e+00\n",
      "Epoch 3/25\n",
      "78/78 [==============================] - 23s 292ms/step - loss: 3.3784 - auc_1: 0.6387 - precision_1: 0.5711 - recall_1: 8.0699e-04\n",
      "Epoch 4/25\n",
      "78/78 [==============================] - 22s 283ms/step - loss: 2.9653 - auc_1: 0.7159 - precision_1: 0.7571 - recall_1: 0.0057\n",
      "Epoch 5/25\n",
      "78/78 [==============================] - 22s 287ms/step - loss: 2.6206 - auc_1: 0.7666 - precision_1: 0.8173 - recall_1: 0.0162\n",
      "Epoch 6/25\n",
      "78/78 [==============================] - 22s 288ms/step - loss: 2.4174 - auc_1: 0.8019 - precision_1: 0.8014 - recall_1: 0.0298\n",
      "Epoch 7/25\n",
      "78/78 [==============================] - 23s 295ms/step - loss: 2.2432 - auc_1: 0.8270 - precision_1: 0.7768 - recall_1: 0.0442\n",
      "Epoch 8/25\n",
      "78/78 [==============================] - 25s 314ms/step - loss: 2.1201 - auc_1: 0.8462 - precision_1: 0.7682 - recall_1: 0.0581\n",
      "Epoch 9/25\n",
      "78/78 [==============================] - 24s 307ms/step - loss: 1.9937 - auc_1: 0.8613 - precision_1: 0.7718 - recall_1: 0.0727\n",
      "Epoch 10/25\n",
      "78/78 [==============================] - 24s 303ms/step - loss: 1.9191 - auc_1: 0.8732 - precision_1: 0.7713 - recall_1: 0.0868\n",
      "Epoch 11/25\n",
      "78/78 [==============================] - 24s 304ms/step - loss: 1.8117 - auc_1: 0.8832 - precision_1: 0.7737 - recall_1: 0.1022\n",
      "Epoch 12/25\n",
      "78/78 [==============================] - 37s 475ms/step - loss: 1.7874 - auc_1: 0.8916 - precision_1: 0.7742 - recall_1: 0.1164\n",
      "Epoch 13/25\n",
      "78/78 [==============================] - 26s 336ms/step - loss: 1.7032 - auc_1: 0.8985 - precision_1: 0.7739 - recall_1: 0.1288\n",
      "Epoch 14/25\n",
      "78/78 [==============================] - 25s 326ms/step - loss: 1.6505 - auc_1: 0.9047 - precision_1: 0.7761 - recall_1: 0.1425\n",
      "Epoch 15/25\n",
      "78/78 [==============================] - 28s 355ms/step - loss: 1.5938 - auc_1: 0.9101 - precision_1: 0.7780 - recall_1: 0.1548\n",
      "Epoch 16/25\n",
      "78/78 [==============================] - 28s 360ms/step - loss: 1.5376 - auc_1: 0.9149 - precision_1: 0.7822 - recall_1: 0.1672\n",
      "Epoch 17/25\n",
      "78/78 [==============================] - 30s 378ms/step - loss: 1.5115 - auc_1: 0.9190 - precision_1: 0.7848 - recall_1: 0.1786\n",
      "Epoch 18/25\n",
      "78/78 [==============================] - 29s 367ms/step - loss: 1.4508 - auc_1: 0.9230 - precision_1: 0.7863 - recall_1: 0.1897\n",
      "Epoch 19/25\n",
      "78/78 [==============================] - 28s 363ms/step - loss: 1.3926 - auc_1: 0.9266 - precision_1: 0.7894 - recall_1: 0.2010\n",
      "Epoch 20/25\n",
      "78/78 [==============================] - 28s 363ms/step - loss: 1.3801 - auc_1: 0.9298 - precision_1: 0.7914 - recall_1: 0.2113\n",
      "Epoch 21/25\n",
      "78/78 [==============================] - 30s 390ms/step - loss: 1.3059 - auc_1: 0.9328 - precision_1: 0.7933 - recall_1: 0.2219\n",
      "Epoch 22/25\n",
      "78/78 [==============================] - 29s 377ms/step - loss: 1.2852 - auc_1: 0.9356 - precision_1: 0.7946 - recall_1: 0.2320\n",
      "Epoch 23/25\n",
      "78/78 [==============================] - 29s 368ms/step - loss: 1.2341 - auc_1: 0.9381 - precision_1: 0.7951 - recall_1: 0.2416\n",
      "Epoch 24/25\n",
      "78/78 [==============================] - 29s 366ms/step - loss: 1.2159 - auc_1: 0.9405 - precision_1: 0.7978 - recall_1: 0.2516\n",
      "Epoch 25/25\n",
      "78/78 [==============================] - 30s 384ms/step - loss: 1.1979 - auc_1: 0.9427 - precision_1: 0.7993 - recall_1: 0.2606\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1f86d72bac8>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnn.fit(x=train_set, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f872b94088>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import idx2numpy\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "imagefile = 't10k-images.idx3-ubyte'\n",
    "imagearray = idx2numpy.convert_from_file(imagefile)\n",
    "\n",
    "plt.imshow(imagearray[4], cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Making a sinle prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing import image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(imagearray[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = imagearray[0:32, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch1 = np.expand_dims(batch1, axis=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cnn.predict(batch1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 1., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 62)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1f87310bbc8>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.squeeze(batch1[14], axis=2), cmap=plt.cm.binary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(result[14])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(result[14] == np.max(result[14]))[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_list[18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
